{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 04\n",
    "# Pipelines and OOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create three custom transformers, the first two out of which will be used within a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "1. `FeatureExtractor()` class:\n",
    " - Takes a dataframe with `uid`, `labname`, `numTrials`, `timestamp` from the file [`checker_submits.csv`](https://drive.google.com/file/d/14voc4fNJZiLEFaZyd8nEG-lQt5JjatYw/view?usp=sharing).\n",
    " - Extracts `hour` from `timestamp`.\n",
    " - Extracts `weekday` from `timestamp` (numbers).\n",
    " - Drops the `timestamp` column.\n",
    " - Returns the new dataframe.\n",
    "\n",
    "\n",
    "2. `MyOneHotEncoder()` class:\n",
    " - Takes the dataframe from the result of the previous transformation and the name of the target column.\n",
    " - Identifies all the categorical features and transforms them with `OneHotEncoder()`. If the target column is categorical too, then the transformation should not apply to it.\n",
    " - Drops the initial categorical features.\n",
    " - Returns the dataframe with the features and the series with the target column.\n",
    "\n",
    "\n",
    "3. `TrainValidationTest()` class:\n",
    " - Takes `X` and `y`.\n",
    " - Returns `X_train`, `X_valid`, `X_test`, `y_train`, `y_valid`, `y_test` (`test_size=0.2`, `random_state=21`, `stratified`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['timestamp'] = pd.to_datetime(X['timestamp'], errors='coerce')\n",
    "        X['hour'] = X['timestamp'].dt.hour\n",
    "        X['dayofweek'] = X['timestamp'].dt.weekday\n",
    "        X = X.drop(columns=['timestamp'])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, target):\n",
    "        self.target = target\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.categorical_features = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        features = X.drop(columns=[self.target])\n",
    "        self.categorical_features = features.select_dtypes(include=['object']).columns.tolist()\n",
    "        if self.categorical_features:\n",
    "            self.encoder.fit(features[self.categorical_features])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        y = X[self.target]\n",
    "        features = X.drop(columns=[self.target])\n",
    "        if self.categorical_features:\n",
    "            encoded = self.encoder.transform(features[self.categorical_features])\n",
    "            encoded_cols = self.encoder.get_feature_names_out(self.categorical_features)\n",
    "            encoded_df = pd.DataFrame(encoded, columns=encoded_cols, index=features.index)\n",
    "            features = features.drop(columns=self.categorical_features)\n",
    "            features = pd.concat([features, encoded_df], axis=1)\n",
    "            df = pd.concat([features, y], axis=1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainValidationTest:\n",
    "    def __init__(self, test_size=0.2, random_state=21, stratified=True):\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.stratified = stratified\n",
    "    \n",
    "    def split_train_valid_test(self, X, y):\n",
    "        stratify = y if self.stratified else None\n",
    "        X_train_valid, X_test, y_train_valid, y_test = train_test_split(\n",
    "            X, y, \n",
    "            test_size=self.test_size, \n",
    "            random_state=self.random_state,\n",
    "            stratify=stratify\n",
    "        )\n",
    "        \n",
    "        valid_size = self.test_size / (1 - self.test_size)\n",
    "        stratify = y_train_valid if self.stratified else None\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X_train_valid, y_train_valid, \n",
    "            test_size=valid_size, \n",
    "            random_state=self.random_state,\n",
    "            stratify=stratify\n",
    "        )\n",
    "        return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model selection pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelSelection()` class\n",
    "\n",
    " - Takes a list of `GridSearchCV` instances and a dict where the keys are the indexes from that list and the values are the names of the models, the example is below in the reverse order (from high-level to low-level perspective):\n",
    "\n",
    "```\n",
    "ModelSelection(grids, grid_dict)\n",
    "\n",
    "grids = [gs_svm, gs_tree, gs_rf]\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=svm, param_grid=svm_params, scoring='accuracy', cv=2, n_jobs=jobs), where jobs you can specify by yourself\n",
    "\n",
    "svm_params = [{'kernel':('linear', 'rbf', 'sigmoid'), 'C':[0.01, 0.1, 1, 1.5, 5, 10], 'gamma': ['scale', 'auto'], 'class_weight':('balanced', None), 'random_state':[21], 'probability':[True]}]\n",
    "```\n",
    "\n",
    " - Method `choose()` takes `X_train`, `y_train`, `X_valid`, `y_valid` and returns the name of the best classifier among all the models on the validation set\n",
    " - Method `best_results()` returns a dataframe with the columns `model`, `params`, `valid_score` where the rows are the best models within each class of models.\n",
    "\n",
    "```\n",
    "model\tparams\tvalid_score\n",
    "0\tSVM\t{'C': 10, 'class_weight': None, 'gamma': 'auto...\t0.772727\n",
    "1\tDecision Tree\t{'class_weight': 'balanced', 'criterion': 'gin...\t0.801484\n",
    "2\tRandom Forest\t{'class_weight': None, 'criterion': 'entropy',...\t0.855288\n",
    "```\n",
    "\n",
    " - When you iterate through the parameters of a model class, print the name of that class and show the progress using `tqdm.notebook`, in the end of the cycle print the best model of that class.\n",
    "\n",
    "```\n",
    "Estimator: SVM\n",
    "100%\n",
    "125/125 [01:32<00:00, 1.36it/s]\n",
    "Best params: {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 21}\n",
    "Best training accuracy: 0.773\n",
    "Validation set accuracy score for best params: 0.878 \n",
    "\n",
    "Estimator: Decision Tree\n",
    "100%\n",
    "57/57 [01:07<00:00, 1.22it/s]\n",
    "Best params: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 21, 'random_state': 21}\n",
    "Best training accuracy: 0.801\n",
    "Validation set accuracy score for best params: 0.867 \n",
    "\n",
    "Estimator: Random Forest\n",
    "100%\n",
    "284/284 [06:47<00:00, 1.13s/it]\n",
    "Best params: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 22, 'n_estimators': 50, 'random_state': 21}\n",
    "Best training accuracy: 0.855\n",
    "Validation set accuracy score for best params: 0.907 \n",
    "\n",
    "Classifier with best validation set accuracy: Random Forest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelection:\n",
    "\n",
    "    def __init__(self, grids, grid_dict):\n",
    "        self.grids = grids\n",
    "        self.grids_dict = grid_dict\n",
    "        self.results = []\n",
    "\n",
    "    def choose(self, X_train, y_train, X_valid, y_valid):\n",
    "        for grid, estimator_name in zip(self.grids, self.grids_dict.values()):\n",
    "            print(f'Estimator: {estimator_name}')\n",
    "            \n",
    "            grid.fit(X_train, y_train)\n",
    "            valid_score = grid.score(X_valid, y_valid)\n",
    "\n",
    "            self.results.append({\n",
    "                'model': estimator_name,\n",
    "                'params': grid.best_params_,\n",
    "                'train_score': grid.best_score_,\n",
    "                'valid_score': valid_score\n",
    "            })\n",
    "            \n",
    "            print(f'Best params: {grid.best_params_}')\n",
    "            print(f'Best training accuracy: {grid.best_score_:.3f}')\n",
    "            print(f'Validation set accuracy score for best params: {valid_score:.3f}')\n",
    "            print()\n",
    "\n",
    "    def best_results(self):\n",
    "        results_df = pd.DataFrame(self.results)\n",
    "        \n",
    "        best_model = results_df.loc[results_df['valid_score'].idxmax()]\n",
    "        print(f'Classifier with best validation set accuracy: {best_model[\"model\"]}')\n",
    "        \n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "tree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "svm_params = {\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "    'C': [0.01, 0.1, 1, 1.5, 5, 10],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'random_state': [21],\n",
    "    'probability': [True]\n",
    "}\n",
    "\n",
    "tree_params = {\n",
    "    'max_depth': np.arange(1, 50),\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'random_state': [21]\n",
    "}\n",
    "\n",
    "rf_params =  {\n",
    "    'n_estimators': [5, 10, 50, 100],\n",
    "    'max_depth': np.arange(1, 50),\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'random_state': [21]\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=svm, param_grid=svm_params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "gs_tree = GridSearchCV(estimator=tree, param_grid=tree_params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "gs_rf = GridSearchCV(estimator=rf, param_grid=rf_params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "grids = [gs_svm, gs_tree, gs_rf]\n",
    "grids_dict = {0: 'SVC', 1: 'DecisionTreeClassifier', 2: 'RandomForestClassifier'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Finalize()` class\n",
    " - Takes an estimator.\n",
    " - Method `final_score()` takes `X_train`, `y_train`, `X_test`, `y_test` and returns the accuracy of the model as in the example below:\n",
    "```\n",
    "final.final_score(X_train, y_train, X_test, y_test)\n",
    "Accuracy of the final model is 0.908284023668639\n",
    "```\n",
    " - Method `save_model()` takes a path, saves the model to this path and prints that the model was successfully saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Finalize:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def final_score(self, X_train, X_test, y_train, y_test):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        score = self.model.score(X_test, y_test)\n",
    "        print(f'Accuracy of the final model is: {score}')\n",
    "        return score\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        joblib.dump(self.model, path)\n",
    "        if os.path.exists and os.path.getsize(path) > 0:\n",
    "            print('The model was successfully saved')\n",
    "        else:\n",
    "            print('Error: not model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data from the file (****name of file****).\n",
    "2. Create the preprocessing pipeline that consists of two custom transformers: `FeatureExtractor()` and `MyOneHotEncoder()`:\n",
    "```\n",
    "preprocessing = Pipeline([('feature_extractor', FeatureExtractor()), ('onehot_encoder', MyOneHotEncoder('dayofweek'))])\n",
    "```\n",
    "3. Use that pipeline and its method `fit_transform()` on the initial dataset.\n",
    "```\n",
    "data = preprocessing.fit_transform(df)\n",
    "```\n",
    "4. Get `X_train`, `X_valid`, `X_test`, `y_train`, `y_valid`, `y_test` using `TrainValidationTest()` and the result of the pipeline.\n",
    "5. Create an instance of `ModelSelection()`, use the method `choose()` applying it to the models that you want and parameters that you want, get the dataframe of the best results.\n",
    "6. create an instance of `Finalize()` with your best model, use method `final_score()` and save the model in the format: `name_of_the_model_{accuracy on test dataset}.sav`.\n",
    "\n",
    "That is it, congrats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>uid_user_15</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   numTrials  hour  uid_user_0  uid_user_1  uid_user_10  uid_user_11  \\\n",
       "0          1     5         0.0         0.0          0.0          0.0   \n",
       "1          2     5         0.0         0.0          0.0          0.0   \n",
       "2          3     5         0.0         0.0          0.0          0.0   \n",
       "3          4     5         0.0         0.0          0.0          0.0   \n",
       "4          5     5         0.0         0.0          0.0          0.0   \n",
       "\n",
       "   uid_user_12  uid_user_13  uid_user_14  uid_user_15  ...  labname_lab03  \\\n",
       "0          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "2          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "3          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "4          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "\n",
       "   labname_lab03s  labname_lab05s  labname_laba04  labname_laba04s  \\\n",
       "0             0.0             0.0             0.0              0.0   \n",
       "1             0.0             0.0             0.0              0.0   \n",
       "2             0.0             0.0             0.0              0.0   \n",
       "3             0.0             0.0             0.0              0.0   \n",
       "4             0.0             0.0             0.0              0.0   \n",
       "\n",
       "   labname_laba05  labname_laba06  labname_laba06s  labname_project1  \\\n",
       "0             0.0             0.0              0.0               1.0   \n",
       "1             0.0             0.0              0.0               1.0   \n",
       "2             0.0             0.0              0.0               1.0   \n",
       "3             0.0             0.0              0.0               1.0   \n",
       "4             0.0             0.0              0.0               1.0   \n",
       "\n",
       "   dayofweek  \n",
       "0          4  \n",
       "1          4  \n",
       "2          4  \n",
       "3          4  \n",
       "4          4  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/checker_submits.csv', parse_dates=['timestamp'])\n",
    "\n",
    "preprocessing = Pipeline([('feature_extractor', FeatureExtractor()), ('onehot_encoder', MyOneHotEncoder('dayofweek'))])\n",
    "data = preprocessing.fit_transform(df)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('dayofweek', axis=1)\n",
    "y = data['dayofweek']\n",
    "splitter = TrainValidationTest()\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = splitter.split_train_valid_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: SVC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 10, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 21}\n",
      "Best training accuracy: 0.834\n",
      "Validation set accuracy score for best params: 0.831\n",
      "\n",
      "Estimator: DecisionTreeClassifier\n",
      "Best params: {'class_weight': None, 'criterion': 'gini', 'max_depth': 21, 'random_state': 21}\n",
      "Best training accuracy: 0.858\n",
      "Validation set accuracy score for best params: 0.864\n",
      "\n",
      "Estimator: RandomForestClassifier\n",
      "Best params: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 27, 'n_estimators': 100, 'random_state': 21}\n",
      "Best training accuracy: 0.892\n",
      "Validation set accuracy score for best params: 0.884\n",
      "\n",
      "Classifier with best validation set accuracy: RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "selection = ModelSelection(grids, grids_dict)\n",
    "selection.choose(X_train, y_train, X_valid, y_valid)\n",
    "model_df = selection.best_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the final model is: 0.9053254437869822\n",
      "The model was successfully saved\n"
     ]
    }
   ],
   "source": [
    "final = Finalize(RandomForestClassifier(class_weight=None, criterion='entropy', max_depth=27, n_estimators=100, random_state=21))\n",
    "accuracy = final.final_score(X_train, X_test, y_train, y_test)\n",
    "final.save_model(f'../data/final_model_{accuracy:.5f}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
